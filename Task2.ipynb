{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "---\n",
    "\n",
    "## Predictive modeling of customer bookings\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with this predictive modeling task. We will use various packages for data manipulation, feature engineering and machine learning.\n",
    "\n",
    "### Exploratory data analysis\n",
    "\n",
    "First, we must explore the data in order to better understand what we have and the statistical properties of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import classification_report,accuracy_score,roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression,RidgeClassifier,SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,BaggingClassifier,GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_passengers</th>\n",
       "      <th>sales_channel</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>purchase_lead</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>flight_hour</th>\n",
       "      <th>flight_day</th>\n",
       "      <th>route</th>\n",
       "      <th>booking_origin</th>\n",
       "      <th>wants_extra_baggage</th>\n",
       "      <th>wants_preferred_seat</th>\n",
       "      <th>wants_in_flight_meals</th>\n",
       "      <th>flight_duration</th>\n",
       "      <th>booking_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Internet</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>262</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>Sat</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Internet</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>112</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>Sat</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Internet</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>243</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>Wed</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Internet</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>96</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>Sat</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Internet</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>68</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>Wed</td>\n",
       "      <td>AKLDEL</td>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_passengers sales_channel  trip_type  purchase_lead  length_of_stay  \\\n",
       "0               2      Internet  RoundTrip            262              19   \n",
       "1               1      Internet  RoundTrip            112              20   \n",
       "2               2      Internet  RoundTrip            243              22   \n",
       "3               1      Internet  RoundTrip             96              31   \n",
       "4               2      Internet  RoundTrip             68              22   \n",
       "\n",
       "   flight_hour flight_day   route booking_origin  wants_extra_baggage  \\\n",
       "0            7        Sat  AKLDEL    New Zealand                    1   \n",
       "1            3        Sat  AKLDEL    New Zealand                    0   \n",
       "2           17        Wed  AKLDEL          India                    1   \n",
       "3            4        Sat  AKLDEL    New Zealand                    0   \n",
       "4           15        Wed  AKLDEL          India                    1   \n",
       "\n",
       "   wants_preferred_seat  wants_in_flight_meals  flight_duration  \\\n",
       "0                     0                      0             5.52   \n",
       "1                     0                      0             5.52   \n",
       "2                     1                      0             5.52   \n",
       "3                     0                      1             5.52   \n",
       "4                     0                      1             5.52   \n",
       "\n",
       "   booking_complete  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"customer_booking.csv\", encoding=\"ISO-8859-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.head()` method allows us to view the first 5 rows in the dataset, this is useful for visual inspection of our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   num_passengers         50000 non-null  int64  \n",
      " 1   sales_channel          50000 non-null  object \n",
      " 2   trip_type              50000 non-null  object \n",
      " 3   purchase_lead          50000 non-null  int64  \n",
      " 4   length_of_stay         50000 non-null  int64  \n",
      " 5   flight_hour            50000 non-null  int64  \n",
      " 6   flight_day             50000 non-null  object \n",
      " 7   route                  50000 non-null  object \n",
      " 8   booking_origin         50000 non-null  object \n",
      " 9   wants_extra_baggage    50000 non-null  int64  \n",
      " 10  wants_preferred_seat   50000 non-null  int64  \n",
      " 11  wants_in_flight_meals  50000 non-null  int64  \n",
      " 12  flight_duration        50000 non-null  float64\n",
      " 13  booking_complete       50000 non-null  int64  \n",
      "dtypes: float64(1), int64(8), object(5)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.info()` method gives us a data description, telling us the names of the columns, their data types and how many null values we have. Fortunately, we have no null values. It looks like some of these columns should be converted into different data types, e.g. flight_day.\n",
    "\n",
    "To provide more context, below is a more detailed data description, explaining exactly what each column means:\n",
    "\n",
    "- `num_passengers` = number of passengers travelling\n",
    "- `sales_channel` = sales channel booking was made on\n",
    "- `trip_type` = trip Type (Round Trip, One Way, Circle Trip)\n",
    "- `purchase_lead` = number of days between travel date and booking date\n",
    "- `length_of_stay` = number of days spent at destination\n",
    "- `flight_hour` = hour of flight departure\n",
    "- `flight_day` = day of week of flight departure\n",
    "- `route` = origin -> destination flight route\n",
    "- `booking_origin` = country from where booking was made\n",
    "- `wants_extra_baggage` = if the customer wanted extra baggage in the booking\n",
    "- `wants_preferred_seat` = if the customer wanted a preferred seat in the booking\n",
    "- `wants_in_flight_meals` = if the customer wanted in-flight meals in the booking\n",
    "- `flight_duration` = total duration of flight (in hours)\n",
    "- `booking_complete` = flag indicating if the customer completed the booking\n",
    "\n",
    "Before we compute any statistics on the data, lets do any necessary data conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_passengers</th>\n",
       "      <th>sales_channel</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>purchase_lead</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>flight_hour</th>\n",
       "      <th>flight_day</th>\n",
       "      <th>route</th>\n",
       "      <th>booking_origin</th>\n",
       "      <th>wants_extra_baggage</th>\n",
       "      <th>wants_preferred_seat</th>\n",
       "      <th>wants_in_flight_meals</th>\n",
       "      <th>flight_duration</th>\n",
       "      <th>booking_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>799</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Internet</td>\n",
       "      <td>RoundTrip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mon</td>\n",
       "      <td>AKLKUL</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44382</td>\n",
       "      <td>49497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8102</td>\n",
       "      <td>2680</td>\n",
       "      <td>17872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.591240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.940480</td>\n",
       "      <td>23.04456</td>\n",
       "      <td>9.06634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.668780</td>\n",
       "      <td>0.296960</td>\n",
       "      <td>0.427140</td>\n",
       "      <td>7.277561</td>\n",
       "      <td>0.149560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.020165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.451378</td>\n",
       "      <td>33.88767</td>\n",
       "      <td>5.41266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470657</td>\n",
       "      <td>0.456923</td>\n",
       "      <td>0.494668</td>\n",
       "      <td>1.496863</td>\n",
       "      <td>0.356643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.670000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.620000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.830000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>867.000000</td>\n",
       "      <td>778.00000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_passengers sales_channel  trip_type  purchase_lead  \\\n",
       "count     50000.000000         50000      50000   50000.000000   \n",
       "unique             NaN             2          3            NaN   \n",
       "top                NaN      Internet  RoundTrip            NaN   \n",
       "freq               NaN         44382      49497            NaN   \n",
       "mean          1.591240           NaN        NaN      84.940480   \n",
       "std           1.020165           NaN        NaN      90.451378   \n",
       "min           1.000000           NaN        NaN       0.000000   \n",
       "25%           1.000000           NaN        NaN      21.000000   \n",
       "50%           1.000000           NaN        NaN      51.000000   \n",
       "75%           2.000000           NaN        NaN     115.000000   \n",
       "max           9.000000           NaN        NaN     867.000000   \n",
       "\n",
       "        length_of_stay  flight_hour flight_day   route booking_origin  \\\n",
       "count      50000.00000  50000.00000      50000   50000          50000   \n",
       "unique             NaN          NaN          7     799            104   \n",
       "top                NaN          NaN        Mon  AKLKUL      Australia   \n",
       "freq               NaN          NaN       8102    2680          17872   \n",
       "mean          23.04456      9.06634        NaN     NaN            NaN   \n",
       "std           33.88767      5.41266        NaN     NaN            NaN   \n",
       "min            0.00000      0.00000        NaN     NaN            NaN   \n",
       "25%            5.00000      5.00000        NaN     NaN            NaN   \n",
       "50%           17.00000      9.00000        NaN     NaN            NaN   \n",
       "75%           28.00000     13.00000        NaN     NaN            NaN   \n",
       "max          778.00000     23.00000        NaN     NaN            NaN   \n",
       "\n",
       "        wants_extra_baggage  wants_preferred_seat  wants_in_flight_meals  \\\n",
       "count          50000.000000          50000.000000           50000.000000   \n",
       "unique                  NaN                   NaN                    NaN   \n",
       "top                     NaN                   NaN                    NaN   \n",
       "freq                    NaN                   NaN                    NaN   \n",
       "mean               0.668780              0.296960               0.427140   \n",
       "std                0.470657              0.456923               0.494668   \n",
       "min                0.000000              0.000000               0.000000   \n",
       "25%                0.000000              0.000000               0.000000   \n",
       "50%                1.000000              0.000000               0.000000   \n",
       "75%                1.000000              1.000000               1.000000   \n",
       "max                1.000000              1.000000               1.000000   \n",
       "\n",
       "        flight_duration  booking_complete  \n",
       "count      50000.000000      50000.000000  \n",
       "unique              NaN               NaN  \n",
       "top                 NaN               NaN  \n",
       "freq                NaN               NaN  \n",
       "mean           7.277561          0.149560  \n",
       "std            1.496863          0.356643  \n",
       "min            4.670000          0.000000  \n",
       "25%            5.620000          0.000000  \n",
       "50%            7.570000          0.000000  \n",
       "75%            8.830000          0.000000  \n",
       "max            9.500000          1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.describe()` method gives us a summary of descriptive statistics over the entire dataset (only works for numeric columns). This gives us a quick overview of a few things such as the mean, min, max and overall distribution of each column.\n",
    "\n",
    "From this point, you should continue exploring the dataset with some visualisations and other metrics that you think may be useful. Then, you should prepare your dataset for predictive modelling. Finally, you should train your machine learning model, evaluate it with performance metrics and output visualisations for the contributing variables. All of this analysis should be summarised in your single slide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding NULL Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_passengers           0\n",
       "sales_channel            0\n",
       "trip_type                0\n",
       "purchase_lead            0\n",
       "length_of_stay           0\n",
       "flight_hour              0\n",
       "flight_day               0\n",
       "route                    0\n",
       "booking_origin           0\n",
       "wants_extra_baggage      0\n",
       "wants_preferred_seat     0\n",
       "wants_in_flight_meals    0\n",
       "flight_duration          0\n",
       "booking_complete         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Flight_Day Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sat', 'Wed', 'Thu', 'Mon', 'Sun', 'Tue', 'Fri'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"flight_day\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"Mon\": 1,\n",
    "    \"Tue\": 2,\n",
    "    \"Wed\": 3,\n",
    "    \"Thu\": 4,\n",
    "    \"Fri\": 5,\n",
    "    \"Sat\": 6,\n",
    "    \"Sun\": 7\n",
    "}\n",
    "\n",
    "df[\"flight_day\"] = df[\"flight_day\"].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 3, 4, 1, 7, 2, 5], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"flight_day\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Sales_Channel Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Internet', 'Mobile'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sales_channel\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"Internet\": 0,\n",
    "    \"Mobile\": 1\n",
    "}\n",
    "\n",
    "df[\"sales_channel\"] = df[\"sales_channel\"].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sales_channel\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Trip_Type Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RoundTrip', 'CircleTrip', 'OneWay'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"trip_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"OneWay\": 0,\n",
    "    \"CircleTrip\": 1,\n",
    "    \"RoundTrip\":2    \n",
    "}\n",
    "\n",
    "df[\"trip_type\"] = df[\"trip_type\"].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"trip_type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Route Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AKLDEL', 'AKLHGH', 'AKLHND', 'AKLICN', 'AKLKIX', 'AKLKTM',\n",
       "       'AKLKUL', 'AKLMRU', 'AKLPEK', 'AKLPVG', 'AKLTPE', 'AORICN',\n",
       "       'AORKIX', 'AORKTM', 'AORMEL', 'BBIMEL', 'BBIOOL', 'BBIPER',\n",
       "       'BBISYD', 'BDOCTS', 'BDOCTU', 'BDOHGH', 'BDOICN', 'BDOIKA',\n",
       "       'BDOKIX', 'BDOMEL', 'BDOOOL', 'BDOPEK', 'BDOPER', 'BDOPUS',\n",
       "       'BDOPVG', 'BDOSYD', 'BDOTPE', 'BDOXIY', 'BKICKG', 'BKICTS',\n",
       "       'BKICTU', 'BKIHND', 'BKIICN', 'BKIKIX', 'BKIKTM', 'BKIMEL',\n",
       "       'BKIMRU', 'BKIOOL', 'BKIPEK', 'BKIPER', 'BKIPUS', 'BKIPVG',\n",
       "       'BKISYD', 'BKIXIY', 'BLRICN', 'BLRMEL', 'BLRPER', 'BLRSYD',\n",
       "       'BOMMEL', 'BOMOOL', 'BOMPER', 'BOMSYD', 'BTJJED', 'BTUICN',\n",
       "       'BTUPER', 'BTUSYD', 'BTUWUH', 'BWNCKG', 'BWNDEL', 'BWNHGH',\n",
       "       'BWNIKA', 'BWNKTM', 'BWNMEL', 'BWNOOL', 'BWNPER', 'BWNSYD',\n",
       "       'BWNTPE', 'CANDEL', 'CANIKA', 'CANMEL', 'CANMRU', 'CANOOL',\n",
       "       'CANPER', 'CANSYD', 'CCUMEL', 'CCUMRU', 'CCUOOL', 'CCUPER',\n",
       "       'CCUSYD', 'CCUTPE', 'CEBMEL', 'CEBOOL', 'CEBPER', 'CEBSYD',\n",
       "       'CGKCKG', 'CGKCTS', 'CGKCTU', 'CGKDEL', 'CGKHGH', 'CGKHND',\n",
       "       'CGKICN', 'CGKIKA', 'CGKJED', 'CGKKIX', 'CGKKTM', 'CGKMEL',\n",
       "       'CGKMRU', 'CGKOOL', 'CGKPEK', 'CGKPER', 'CGKPUS', 'CGKPVG',\n",
       "       'CGKSYD', 'CGKTPE', 'CGKWUH', 'CGKXIY', 'CKGCOK', 'CKGDPS',\n",
       "       'CKGJHB', 'CKGKCH', 'CKGLOP', 'CKGMAA', 'CKGMEL', 'CKGMYY',\n",
       "       'CKGOOL', 'CKGPEN', 'CKGPER', 'CKGPNH', 'CKGSBW', 'CKGSIN',\n",
       "       'CKGSUB', 'CKGSYD', 'CKGTGG', 'CKGTRZ', 'CKGTWU', 'CMBCTS',\n",
       "       'CMBCTU', 'CMBHGH', 'CMBHND', 'CMBICN', 'CMBKIX', 'CMBMEL',\n",
       "       'CMBMRU', 'CMBOOL', 'CMBPEK', 'CMBPER', 'CMBPVG', 'CMBSYD',\n",
       "       'CMBWUH', 'CNXHND', 'CNXICN', 'CNXKIX', 'CNXMEL', 'CNXOOL',\n",
       "       'CNXPEK', 'CNXPER', 'CNXPVG', 'CNXSYD', 'CNXTPE', 'COKCTU',\n",
       "       'COKHGH', 'COKICN', 'COKKIX', 'COKMEL', 'COKOOL', 'COKPER',\n",
       "       'COKPUS', 'COKSYD', 'COKTPE', 'COKWUH', 'CRKMEL', 'CRKOOL',\n",
       "       'CRKSYD', 'CSXPER', 'CTSDMK', 'CTSDPS', 'CTSHKT', 'CTSJHB',\n",
       "       'CTSKBR', 'CTSKCH', 'CTSKNO', 'CTSLGK', 'CTSMEL', 'CTSMYY',\n",
       "       'CTSOOL', 'CTSPEN', 'CTSPER', 'CTSSGN', 'CTSSIN', 'CTSSUB',\n",
       "       'CTSSYD', 'CTUDPS', 'CTUHKT', 'CTUIKA', 'CTUJHB', 'CTUKBV',\n",
       "       'CTUKCH', 'CTUKNO', 'CTUMAA', 'CTUMEL', 'CTUMRU', 'CTUMYY',\n",
       "       'CTUOOL', 'CTUPEN', 'CTUPER', 'CTUSBW', 'CTUSIN', 'CTUSUB',\n",
       "       'CTUSYD', 'CTUTGG', 'CTUTRZ', 'CTUTWU', 'CXRMEL', 'DACHGH',\n",
       "       'DACHND', 'DACICN', 'DACKIX', 'DACMEL', 'DACOOL', 'DACPER',\n",
       "       'DACSYD', 'DACTPE', 'DADMEL', 'DADOOL', 'DADSYD', 'DELDMK',\n",
       "       'DELDPS', 'DELHKG', 'DELHKT', 'DELHND', 'DELJHB', 'DELJOG',\n",
       "       'DELKBV', 'DELKCH', 'DELKIX', 'DELKNO', 'DELLGK', 'DELMEL',\n",
       "       'DELMFM', 'DELMNL', 'DELMRU', 'DELMYY', 'DELOOL', 'DELPEN',\n",
       "       'DELPER', 'DELPNH', 'DELSBW', 'DELSGN', 'DELSIN', 'DELSUB',\n",
       "       'DELSYD', 'DELSZX', 'DMKHGH', 'DMKHND', 'DMKICN', 'DMKIKA',\n",
       "       'DMKKIX', 'DMKKTM', 'DMKMEL', 'DMKMRU', 'DMKOOL', 'DMKPEK',\n",
       "       'DMKPER', 'DMKPUS', 'DMKPVG', 'DMKSYD', 'DMKTPE', 'DPSHGH',\n",
       "       'DPSHND', 'DPSICN', 'DPSIKA', 'DPSKIX', 'DPSKTM', 'DPSMEL',\n",
       "       'DPSMRU', 'DPSOOL', 'DPSPEK', 'DPSPUS', 'DPSPVG', 'DPSSYD',\n",
       "       'DPSTPE', 'DPSXIY', 'GOIKUL', 'GOIMEL', 'GOIOOL', 'GOIPER',\n",
       "       'GOISYD', 'HANKTM', 'HANMEL', 'HANOOL', 'HANPER', 'HANSYD',\n",
       "       'HDYHGH', 'HDYKTM', 'HDYMEL', 'HDYOOL', 'HDYPEK', 'HDYPER',\n",
       "       'HDYPVG', 'HDYSYD', 'HDYTPE', 'HGHHKT', 'HGHJHB', 'HGHJOG',\n",
       "       'HGHKBR', 'HGHKBV', 'HGHKCH', 'HGHKNO', 'HGHLGK', 'HGHLOP',\n",
       "       'HGHMAA', 'HGHMEL', 'HGHMYY', 'HGHOOL', 'HGHPEN', 'HGHPER',\n",
       "       'HGHSBW', 'HGHSUB', 'HGHSYD', 'HGHTRZ', 'HKGIKA', 'HKGKTM',\n",
       "       'HKGMEL', 'HKGMRU', 'HKGOOL', 'HKGPER', 'HKGSYD', 'HKTHND',\n",
       "       'HKTICN', 'HKTKIX', 'HKTKTM', 'HKTMEL', 'HKTMRU', 'HKTOOL',\n",
       "       'HKTPEK', 'HKTPER', 'HKTPUS', 'HKTPVG', 'HKTSYD', 'HKTTPE',\n",
       "       'HKTXIY', 'HNDIKA', 'HNDJOG', 'HNDKBR', 'HNDKBV', 'HNDKCH',\n",
       "       'HNDKNO', 'HNDKTM', 'HNDLGK', 'HNDLOP', 'HNDMAA', 'HNDMEL',\n",
       "       'HNDMLE', 'HNDOOL', 'HNDPEN', 'HNDPER', 'HNDPNH', 'HNDREP',\n",
       "       'HNDRGN', 'HNDSBW', 'HNDSGN', 'HNDSIN', 'HNDSUB', 'HNDSYD',\n",
       "       'HNDTRZ', 'HYDMEL', 'HYDOOL', 'HYDPER', 'HYDSYD', 'HYDWUH',\n",
       "       'ICNIKA', 'ICNJED', 'ICNJHB', 'ICNKBR', 'ICNKBV', 'ICNKCH',\n",
       "       'ICNKNO', 'ICNKTM', 'ICNLGK', 'ICNMAA', 'ICNMEL', 'ICNMLE',\n",
       "       'ICNMYY', 'ICNOOL', 'ICNPEN', 'ICNPER', 'ICNREP', 'ICNRGN',\n",
       "       'ICNSBW', 'ICNSDK', 'ICNSGN', 'ICNSIN', 'ICNSUB', 'ICNSYD',\n",
       "       'ICNTRZ', 'ICNVTZ', 'IKAKCH', 'IKAKIX', 'IKALOP', 'IKAMEL',\n",
       "       'IKAMFM', 'IKAMNL', 'IKAOOL', 'IKAPEK', 'IKAPEN', 'IKAPER',\n",
       "       'IKAPUS', 'IKAPVG', 'IKASGN', 'IKASIN', 'IKASUB', 'IKASYD',\n",
       "       'IKATPE', 'JEDJOG', 'JEDKNO', 'JEDMEL', 'JEDMNL', 'JEDPDG',\n",
       "       'JEDPEN', 'JEDSUB', 'JHBKIX', 'JHBKTM', 'JHBMEL', 'JHBMRU',\n",
       "       'JHBPEK', 'JHBPUS', 'JHBPVG', 'JHBSYD', 'JHBTPE', 'JHBWUH',\n",
       "       'JHBXIY', 'JOGKIX', 'JOGKTM', 'JOGMEL', 'JOGOOL', 'JOGPER',\n",
       "       'JOGPVG', 'JOGSYD', 'JOGTPE', 'KBRKIX', 'KBRKTM', 'KBRMEL',\n",
       "       'KBROOL', 'KBRPEK', 'KBRPER', 'KBRPVG', 'KBRSYD', 'KBRTPE',\n",
       "       'KBVKTM', 'KBVMEL', 'KBVOOL', 'KBVPEK', 'KBVPER', 'KBVPVG',\n",
       "       'KBVSYD', 'KCHKIX', 'KCHKTM', 'KCHMEL', 'KCHMRU', 'KCHOOL',\n",
       "       'KCHPEK', 'KCHPER', 'KCHPUS', 'KCHPVG', 'KCHSYD', 'KCHTPE',\n",
       "       'KCHXIY', 'KHHMEL', 'KHHOOL', 'KHHPER', 'KHHSYD', 'KIXKNO',\n",
       "       'KIXKTM', 'KIXLGK', 'KIXLOP', 'KIXMAA', 'KIXMEL', 'KIXMLE',\n",
       "       'KIXMYY', 'KIXOOL', 'KIXPEN', 'KIXPER', 'KIXPNH', 'KIXREP',\n",
       "       'KIXRGN', 'KIXSBW', 'KIXSGN', 'KIXSIN', 'KIXSUB', 'KIXSYD',\n",
       "       'KIXTGG', 'KIXTRZ', 'KLOMEL', 'KLOOOL', 'KNOKTM', 'KNOMEL',\n",
       "       'KNOOOL', 'KNOPEK', 'KNOPER', 'KNOPUS', 'KNOPVG', 'KNOSYD',\n",
       "       'KNOTPE', 'KNOXIY', 'KOSMEL', 'KOSOOL', 'KOSPEK', 'KOSSYD',\n",
       "       'KTMMEL', 'KTMMFM', 'KTMMYY', 'KTMPEN', 'KTMPER', 'KTMREP',\n",
       "       'KTMSGN', 'KTMSIN', 'KTMSUB', 'KTMSYD', 'KTMTGG', 'KTMTPE',\n",
       "       'KTMURT', 'KWLPER', 'LBUPER', 'LGKMEL', 'LGKOOL', 'LGKPER',\n",
       "       'LGKPUS', 'LGKPVG', 'LGKSYD', 'LGKTPE', 'LOPOOL', 'LOPPEK',\n",
       "       'LOPPVG', 'LOPSYD', 'LOPTPE', 'LOPXIY', 'LPQMEL', 'LPQOOL',\n",
       "       'LPQPER', 'LPQTPE', 'MAAMEL', 'MAAMRU', 'MAAOOL', 'MAAPER',\n",
       "       'MAAPVG', 'MAASYD', 'MAATPE', 'MAAWUH', 'MELMFM', 'MELMLE',\n",
       "       'MELMNL', 'MELMRU', 'MELMYY', 'MELPEK', 'MELPEN', 'MELPNH',\n",
       "       'MELPUS', 'MELPVG', 'MELREP', 'MELRGN', 'MELSBW', 'MELSGN',\n",
       "       'MELSIN', 'MELSUB', 'MELSWA', 'MELSZX', 'MELTGG', 'MELTPE',\n",
       "       'MELTRZ', 'MELTWU', 'MELURT', 'MELUTP', 'MELVTE', 'MELVTZ',\n",
       "       'MELWUH', 'MELXIY', 'MFMOOL', 'MFMPER', 'MFMSYD', 'MLEPEK',\n",
       "       'MLEPER', 'MLESYD', 'MNLMRU', 'MNLOOL', 'MNLPER', 'MNLSYD',\n",
       "       'MRUOOL', 'MRUPEK', 'MRUPEN', 'MRUPER', 'MRUPVG', 'MRUSGN',\n",
       "       'MRUSIN', 'MRUSUB', 'MRUSYD', 'MRUSZX', 'MYYOOL', 'MYYPER',\n",
       "       'MYYPUS', 'MYYSYD', 'MYYXIY', 'NRTSYD', 'OOLPEK', 'OOLPEN',\n",
       "       'OOLPNH', 'OOLPUS', 'OOLPVG', 'OOLREP', 'OOLRGN', 'OOLSBW',\n",
       "       'OOLSDK', 'OOLSGN', 'OOLSIN', 'OOLSUB', 'OOLSZX', 'OOLTGG',\n",
       "       'OOLTPE', 'OOLTRZ', 'OOLTWU', 'OOLURT', 'OOLUTP', 'OOLVTE',\n",
       "       'OOLWUH', 'OOLXIY', 'PEKPEN', 'PEKPER', 'PEKREP', 'PEKRGN',\n",
       "       'PEKSBW', 'PEKSIN', 'PEKSUB', 'PEKSYD', 'PEKTGG', 'PEKTRZ',\n",
       "       'PEKTWU', 'PENPER', 'PENPUS', 'PENPVG', 'PENSYD', 'PENTPE',\n",
       "       'PENWUH', 'PENXIY', 'PERPNH', 'PERPUS', 'PERPVG', 'PERREP',\n",
       "       'PERRGN', 'PERSBW', 'PERSDK', 'PERSGN', 'PERSIN', 'PERSWA',\n",
       "       'PERSZX', 'PERTGG', 'PERTPE', 'PERTRZ', 'PERTWU', 'PERUTP',\n",
       "       'PERVTE', 'PERVTZ', 'PERWUH', 'PERXIY', 'PNHSYD', 'PNHTPE',\n",
       "       'PNKTPE', 'PUSRGN', 'PUSSBW', 'PUSSGN', 'PUSSIN', 'PUSSUB',\n",
       "       'PUSSYD', 'PUSTRZ', 'PVGREP', 'PVGRGN', 'PVGSIN', 'PVGSUB',\n",
       "       'PVGSYD', 'PVGTGG', 'PVGTWU', 'PVGURT', 'REPSYD', 'REPTPE',\n",
       "       'RGNSYD', 'RGNTPE', 'SBWSYD', 'SBWTPE', 'SBWXIY', 'SDKSYD',\n",
       "       'SGNSYD', 'SGNXIY', 'SINSYD', 'SINTPE', 'SINWUH', 'SINXIY',\n",
       "       'SRGTPE', 'SUBSYD', 'SUBTPE', 'SUBXIY', 'SYDSZX', 'SYDTPE',\n",
       "       'SYDTRZ', 'SYDTWU', 'SYDVTE', 'SYDVTZ', 'SYDXIY', 'TGGTPE',\n",
       "       'TGGXIY', 'TPETRZ', 'TPEVTE', 'TRZWUH', 'TRZXIY', 'TWUXIY',\n",
       "       'HGHSGN', 'ICNTGG', 'JHBOOL', 'KBRXIY', 'KBVTPE', 'KIXTWU',\n",
       "       'LBUTPE', 'PVGSGN', 'SBWWUH', 'DELREP', 'DPSWUH', 'HKGJED',\n",
       "       'KBVKIX', 'KBVPUS', 'KIXLPQ', 'LGKPEK', 'LGKXIY', 'LOPPER',\n",
       "       'PEKSGN', 'PERSUB', 'TPETWU', 'BDOWUH', 'BKIDEL', 'CKGSGN',\n",
       "       'CTUKBR', 'CTULGK', 'CTUREP', 'DACMRU', 'DACPEK', 'DELRGN',\n",
       "       'HDYXIY', 'HGHTGG', 'HKTWUH', 'ICNVTE', 'KBRPUS', 'KCHWUH',\n",
       "       'KLOSYD', 'KNOWUH', 'MLETPE', 'SDKTPE', 'SUBWUH', 'TWUWUH',\n",
       "       'AORPUS', 'BTUCKG', 'BWNWUH', 'CKGKNO', 'CKGLGK', 'CNXDEL',\n",
       "       'CNXPUS', 'CTSJOG', 'CTSSBW', 'CTUDMK', 'CTULOP', 'DELKBR',\n",
       "       'DELURT', 'HDYKIX', 'HGHSIN', 'HGHTWU', 'HYDMRU', 'IKASZX',\n",
       "       'KBVWUH', 'KBVXIY', 'KIXLBU', 'LGKWUH', 'MELNRT', 'MLEOOL',\n",
       "       'MRUTPE', 'TPEURT', 'URTXIY', 'AORPER', 'CKGHKT', 'CKGMRU',\n",
       "       'CNXXIY', 'COKCTS', 'CSXMRU', 'CSXSYD', 'CTUMLE', 'CTUSGN',\n",
       "       'CTUSRG', 'CTUURT', 'DACPUS', 'HGHMRU', 'HKTIKA', 'HKTJED',\n",
       "       'ICNMRU', 'JEDMFM', 'KBRWUH', 'KIXMRU', 'KTMTWU', 'MLEPVG',\n",
       "       'MRUXIY'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"route\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE=LabelEncoder()\n",
    "df['route']=LE.fit_transform(df['route'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "        28,  29,  30,  31,  32,  33,  34,  36,  37,  38,  39,  41,  42,\n",
       "        43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "        56,  57,  58,  59,  60,  61,  62,  64,  65,  66,  67,  68,  69,\n",
       "        70,  71,  72,  73,  74,  75,  76,  77,  79,  80,  81,  82,  83,\n",
       "        84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,\n",
       "        97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
       "       110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 125,\n",
       "       126, 127, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140,\n",
       "       141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
       "       154, 155, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 170,\n",
       "       171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
       "       185, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199,\n",
       "       200, 202, 203, 204, 205, 207, 208, 209, 210, 212, 213, 214, 217,\n",
       "       218, 220, 221, 222, 223, 224, 226, 228, 230, 231, 232, 233, 234,\n",
       "       236, 237, 238, 239, 240, 241, 243, 245, 247, 248, 249, 250, 251,\n",
       "       252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265,\n",
       "       266, 267, 268, 269, 270, 271, 272, 273, 276, 277, 278, 279, 280,\n",
       "       281, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
       "       295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
       "       308, 309, 310, 311, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
       "       322, 323, 324, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336,\n",
       "       337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350,\n",
       "       351, 354, 355, 357, 359, 361, 362, 363, 364, 365, 366, 367, 368,\n",
       "       371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384,\n",
       "       385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
       "       398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 410, 411,\n",
       "       412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424,\n",
       "       425, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438,\n",
       "       440, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
       "       454, 455, 456, 457, 458, 460, 461, 462, 463, 465, 466, 467, 468,\n",
       "       469, 470, 471, 472, 474, 475, 476, 477, 478, 479, 480, 481, 482,\n",
       "       483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496,\n",
       "       497, 498, 502, 503, 504, 505, 506, 508, 509, 513, 514, 515, 516,\n",
       "       517, 518, 519, 520, 521, 522, 523, 525, 526, 527, 528, 529, 530,\n",
       "       531, 533, 534, 536, 537, 538, 540, 541, 542, 543, 544, 545, 546,\n",
       "       547, 548, 549, 550, 551, 552, 553, 555, 556, 558, 559, 560, 561,\n",
       "       562, 563, 564, 565, 566, 568, 569, 570, 571, 572, 573, 574, 575,\n",
       "       576, 577, 578, 579, 580, 581, 582, 583, 584, 586, 587, 588, 590,\n",
       "       591, 593, 594, 595, 596, 597, 600, 601, 603, 604, 605, 606, 607,\n",
       "       608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620,\n",
       "       621, 622, 623, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634,\n",
       "       635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647,\n",
       "       648, 649, 650, 652, 653, 655, 657, 658, 659, 660, 661, 662, 663,\n",
       "       664, 665, 666, 667, 668, 669, 670, 673, 674, 675, 676, 677, 678,\n",
       "       679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691,\n",
       "       692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704,\n",
       "       705, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718,\n",
       "       719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 730, 731, 732,\n",
       "       733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745,\n",
       "       746, 747, 748, 749, 750, 751, 752, 754, 755, 756, 757, 758, 759,\n",
       "       760, 761, 762, 763, 764, 765, 767, 768, 770, 771, 772, 773, 774,\n",
       "       775, 776, 777, 778, 780, 781, 782, 783, 784, 785, 786, 787, 788,\n",
       "       789, 790, 793, 794, 795, 797, 352, 439, 473, 500, 510, 554, 589,\n",
       "       753, 766, 274, 312, 360, 501, 507, 535, 592, 599, 602, 706, 729,\n",
       "       791,  35,  40, 135, 211, 215, 225, 242, 244, 275, 334, 356, 382,\n",
       "       441, 495, 524, 557, 567, 656, 769, 779, 796,  16,  63,  78, 123,\n",
       "       124, 156, 164, 191, 201, 206, 216, 259, 282, 325, 353, 358, 409,\n",
       "       459, 511, 512, 532, 598, 624, 651, 671, 792, 798,  15, 120, 128,\n",
       "       168, 169, 184, 186, 219, 227, 229, 235, 246, 346, 369, 370, 426,\n",
       "       464, 499, 539, 585, 654, 672])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"route\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Booking_Origin Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['New Zealand', 'India', 'United Kingdom', 'China', 'South Korea',\n",
       "       'Japan', 'Malaysia', 'Singapore', 'Switzerland', 'Germany',\n",
       "       'Indonesia', 'Czech Republic', 'Vietnam', 'Thailand', 'Spain',\n",
       "       'Romania', 'Ireland', 'Italy', 'Slovakia', 'United Arab Emirates',\n",
       "       'Tonga', 'Réunion', '(not set)', 'Saudi Arabia', 'Netherlands',\n",
       "       'Qatar', 'Hong Kong', 'Philippines', 'Sri Lanka', 'France',\n",
       "       'Croatia', 'United States', 'Laos', 'Hungary', 'Portugal',\n",
       "       'Cyprus', 'Australia', 'Cambodia', 'Poland', 'Belgium', 'Oman',\n",
       "       'Bangladesh', 'Kazakhstan', 'Brazil', 'Turkey', 'Kenya', 'Taiwan',\n",
       "       'Brunei', 'Chile', 'Bulgaria', 'Ukraine', 'Denmark', 'Colombia',\n",
       "       'Iran', 'Bahrain', 'Solomon Islands', 'Slovenia', 'Mauritius',\n",
       "       'Nepal', 'Russia', 'Kuwait', 'Mexico', 'Sweden', 'Austria',\n",
       "       'Lebanon', 'Jordan', 'Greece', 'Mongolia', 'Canada', 'Tanzania',\n",
       "       'Peru', 'Timor-Leste', 'Argentina', 'New Caledonia', 'Macau',\n",
       "       'Myanmar (Burma)', 'Norway', 'Panama', 'Bhutan', 'Norfolk Island',\n",
       "       'Finland', 'Nicaragua', 'Maldives', 'Egypt', 'Israel', 'Tunisia',\n",
       "       'South Africa', 'Papua New Guinea', 'Paraguay', 'Estonia',\n",
       "       'Seychelles', 'Afghanistan', 'Guam', 'Czechia', 'Malta', 'Vanuatu',\n",
       "       'Belarus', 'Pakistan', 'Iraq', 'Ghana', 'Gibraltar', 'Guatemala',\n",
       "       'Algeria', 'Svalbard & Jan Mayen'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['booking_origin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE=LabelEncoder()\n",
    "df['booking_origin']=LE.fit_transform(df['booking_origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 61,  36, 100,  17,  85,  43,  51,  80,  90,  28,  37,  21, 103,\n",
       "        93,  86,  75,  40,  42,  81,  99,  95,  77,   0,  78,  59,  74,\n",
       "        34,  71,  87,  27,  19, 101,  48,  35,  73,  20,   4,  14,  72,\n",
       "         9,  65,   7,  45,  11,  97,  46,  91,  12,  16,  13,  98,  23,\n",
       "        18,  38,   6,  83,  82,  54,  58,  76,  47,  55,  89,   5,  49,\n",
       "        44,  31,  56,  15,  92,  70,  94,   3,  60,  50,  57,  64,  67,\n",
       "        10,  63,  26,  62,  52,  24,  41,  96,  84,  68,  69,  25,  79,\n",
       "         1,  32,  22,  53, 102,   8,  66,  39,  29,  30,  33,   2,  88])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['booking_origin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_passengers</th>\n",
       "      <th>sales_channel</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>purchase_lead</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>flight_hour</th>\n",
       "      <th>flight_day</th>\n",
       "      <th>route</th>\n",
       "      <th>booking_origin</th>\n",
       "      <th>wants_extra_baggage</th>\n",
       "      <th>wants_preferred_seat</th>\n",
       "      <th>wants_in_flight_meals</th>\n",
       "      <th>flight_duration</th>\n",
       "      <th>booking_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>262</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>243</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_passengers  sales_channel  trip_type  purchase_lead  length_of_stay  \\\n",
       "0               2              0          2            262              19   \n",
       "1               1              0          2            112              20   \n",
       "2               2              0          2            243              22   \n",
       "3               1              0          2             96              31   \n",
       "4               2              0          2             68              22   \n",
       "\n",
       "   flight_hour  flight_day  route  booking_origin  wants_extra_baggage  \\\n",
       "0            7           6      0              61                    1   \n",
       "1            3           6      0              61                    0   \n",
       "2           17           3      0              36                    1   \n",
       "3            4           6      0              61                    0   \n",
       "4           15           3      0              36                    1   \n",
       "\n",
       "   wants_preferred_seat  wants_in_flight_meals  flight_duration  \\\n",
       "0                     0                      0             5.52   \n",
       "1                     0                      0             5.52   \n",
       "2                     1                      0             5.52   \n",
       "3                     0                      1             5.52   \n",
       "4                     0                      1             5.52   \n",
       "\n",
       "   booking_complete  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['booking_complete'].values\n",
    "df.drop('booking_complete',inplace=True,axis=1)\n",
    "x=df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train:(40000, 13)\n",
      "Shape of y_train:(40000,)\n",
      "Shape of x_test:(10000, 13)\n",
      "Shape of y_test:(10000,)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)\n",
    "print(f'Shape of x_train:{x_train.shape}')\n",
    "print(f'Shape of y_train:{y_train.shape}')\n",
    "print(f'Shape of x_test:{x_test.shape}')\n",
    "print(f'Shape of y_test:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()\n",
    "rc=RidgeClassifier()\n",
    "sgdc=SGDClassifier()\n",
    "knn=KNeighborsClassifier()\n",
    "svm=SVC()\n",
    "dtc=DecisionTreeClassifier()\n",
    "etc=ExtraTreeClassifier()\n",
    "abc=AdaBoostClassifier()\n",
    "bc=BaggingClassifier()\n",
    "gbc=GradientBoostingClassifier()\n",
    "rfc=RandomForestClassifier()\n",
    "gnb=GaussianNB()\n",
    "mnb=MultinomialNB()\n",
    "models=[lr,rc,sgdc,knn,svm,dtc,etc,abc,bc,gbc,rfc,gnb,mnb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression()\n",
      "\n",
      "Training Accuracy_Score: 0.8497\n",
      "\n",
      "Testing Accuracy_Score: 0.8523\n",
      "\n",
      "Training AUC_Score: 0.49985293252544266\n",
      "\n",
      "Testing AUC_Score: 0.49994134209291413\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92     33998\n",
      "           1       0.00      0.00      0.00      6002\n",
      "\n",
      "    accuracy                           0.85     40000\n",
      "   macro avg       0.42      0.50      0.46     40000\n",
      "weighted avg       0.72      0.85      0.78     40000\n",
      "\n",
      "\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92      8524\n",
      "           1       0.00      0.00      0.00      1476\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.43      0.50      0.46     10000\n",
      "weighted avg       0.73      0.85      0.78     10000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model: RidgeClassifier()\n",
      "\n",
      "Training Accuracy_Score: 0.84995\n",
      "\n",
      "Testing Accuracy_Score: 0.8524\n",
      "\n",
      "Training AUC_Score: 0.5\n",
      "\n",
      "Testing AUC_Score: 0.5\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92     33998\n",
      "           1       0.00      0.00      0.00      6002\n",
      "\n",
      "    accuracy                           0.85     40000\n",
      "   macro avg       0.42      0.50      0.46     40000\n",
      "weighted avg       0.72      0.85      0.78     40000\n",
      "\n",
      "\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92      8524\n",
      "           1       0.00      0.00      0.00      1476\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.43      0.50      0.46     10000\n",
      "weighted avg       0.73      0.85      0.78     10000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model: SGDClassifier()\n",
      "\n",
      "Training Accuracy_Score: 0.848675\n",
      "\n",
      "Testing Accuracy_Score: 0.8497\n",
      "\n",
      "Training AUC_Score: 0.5011021239483695\n",
      "\n",
      "Testing AUC_Score: 0.4989764274695773\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92     33998\n",
      "           1       0.26      0.00      0.01      6002\n",
      "\n",
      "    accuracy                           0.85     40000\n",
      "   macro avg       0.55      0.50      0.46     40000\n",
      "weighted avg       0.76      0.85      0.78     40000\n",
      "\n",
      "\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92      8524\n",
      "           1       0.06      0.00      0.00      1476\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.46      0.50      0.46     10000\n",
      "weighted avg       0.74      0.85      0.78     10000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model: KNeighborsClassifier()\n",
      "\n",
      "Training Accuracy_Score: 0.872575\n",
      "\n",
      "Testing Accuracy_Score: 0.8331\n",
      "\n",
      "Training AUC_Score: 0.6440589523279677\n",
      "\n",
      "Testing AUC_Score: 0.5553417482790501\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93     33998\n",
      "           1       0.66      0.32      0.43      6002\n",
      "\n",
      "    accuracy                           0.87     40000\n",
      "   macro avg       0.77      0.64      0.68     40000\n",
      "weighted avg       0.85      0.87      0.85     40000\n",
      "\n",
      "\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      8524\n",
      "           1       0.36      0.16      0.22      1476\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.61      0.56      0.56     10000\n",
      "weighted avg       0.79      0.83      0.81     10000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model: SVC()\n",
      "\n",
      "Training Accuracy_Score: 0.84995\n",
      "\n",
      "Testing Accuracy_Score: 0.8524\n",
      "\n",
      "Training AUC_Score: 0.5\n",
      "\n",
      "Testing AUC_Score: 0.5\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92     33998\n",
      "           1       0.00      0.00      0.00      6002\n",
      "\n",
      "    accuracy                           0.85     40000\n",
      "   macro avg       0.42      0.50      0.46     40000\n",
      "weighted avg       0.72      0.85      0.78     40000\n",
      "\n",
      "\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92      8524\n",
      "           1       0.00      0.00      0.00      1476\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.43      0.50      0.46     10000\n",
      "weighted avg       0.73      0.85      0.78     10000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model: DecisionTreeClassifier()\n",
      "\n",
      "Training Accuracy_Score: 0.9999\n",
      "\n",
      "Testing Accuracy_Score: 0.7764\n",
      "\n",
      "Training AUC_Score: 0.9996667777407531\n",
      "\n",
      "Testing AUC_Score: 0.579502288453199\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33998\n",
      "           1       1.00      1.00      1.00      6002\n",
      "\n",
      "    accuracy                           1.00     40000\n",
      "   macro avg       1.00      1.00      1.00     40000\n",
      "weighted avg       1.00      1.00      1.00     40000\n",
      "\n",
      "\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      8524\n",
      "           1       0.27      0.30      0.28      1476\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.57      0.58      0.58     10000\n",
      "weighted avg       0.79      0.78      0.78     10000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model: ExtraTreeClassifier()\n",
      "\n",
      "Training Accuracy_Score: 0.9999\n",
      "\n",
      "Testing Accuracy_Score: 0.7724\n",
      "\n",
      "Training AUC_Score: 0.9996667777407531\n",
      "\n",
      "Testing AUC_Score: 0.5606303388233319\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33998\n",
      "           1       1.00      1.00      1.00      6002\n",
      "\n",
      "    accuracy                           1.00     40000\n",
      "   macro avg       1.00      1.00      1.00     40000\n",
      "weighted avg       1.00      1.00      1.00     40000\n",
      "\n",
      "\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87      8524\n",
      "           1       0.24      0.26      0.25      1476\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.56      0.56      0.56     10000\n",
      "weighted avg       0.78      0.77      0.78     10000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model: AdaBoostClassifier()\n",
      "\n",
      "Training Accuracy_Score: 0.8494\n",
      "\n",
      "Testing Accuracy_Score: 0.8499\n",
      "\n",
      "Training AUC_Score: 0.5153169819131411\n",
      "\n",
      "Testing AUC_Score: 0.5105776579821172\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92     33998\n",
      "           1       0.48      0.04      0.07      6002\n",
      "\n",
      "    accuracy                           0.85     40000\n",
      "   macro avg       0.67      0.52      0.49     40000\n",
      "weighted avg       0.80      0.85      0.79     40000\n",
      "\n",
      "\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      8524\n",
      "           1       0.39      0.03      0.05      1476\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.62      0.51      0.49     10000\n",
      "weighted avg       0.79      0.85      0.79     10000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model: BaggingClassifier()\n",
      "\n",
      "Training Accuracy_Score: 0.98435\n",
      "\n",
      "Testing Accuracy_Score: 0.8436\n",
      "\n",
      "Training AUC_Score: 0.9491540939576213\n",
      "\n",
      "Testing AUC_Score: 0.562341114964411\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     33998\n",
      "           1       1.00      0.90      0.95      6002\n",
      "\n",
      "    accuracy                           0.98     40000\n",
      "   macro avg       0.99      0.95      0.97     40000\n",
      "weighted avg       0.98      0.98      0.98     40000\n",
      "\n",
      "\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91      8524\n",
      "           1       0.42      0.16      0.24      1476\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.65      0.56      0.57     10000\n",
      "weighted avg       0.80      0.84      0.81     10000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model: GradientBoostingClassifier()\n",
      "\n",
      "Training Accuracy_Score: 0.851425\n",
      "\n",
      "Testing Accuracy_Score: 0.852\n",
      "\n",
      "Training AUC_Score: 0.5180860012562435\n",
      "\n",
      "Testing AUC_Score: 0.5129298559527126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92     33998\n",
      "           1       0.57      0.04      0.08      6002\n",
      "\n",
      "    accuracy                           0.85     40000\n",
      "   macro avg       0.71      0.52      0.50     40000\n",
      "weighted avg       0.81      0.85      0.79     40000\n",
      "\n",
      "\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      8524\n",
      "           1       0.48      0.03      0.06      1476\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.67      0.51      0.49     10000\n",
      "weighted avg       0.80      0.85      0.79     10000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model: RandomForestClassifier()\n",
      "\n",
      "Training Accuracy_Score: 0.99985\n",
      "\n",
      "Testing Accuracy_Score: 0.8537\n",
      "\n",
      "Training AUC_Score: 0.9997059630631976\n",
      "\n",
      "Testing AUC_Score: 0.5427768748593164\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33998\n",
      "           1       1.00      1.00      1.00      6002\n",
      "\n",
      "    accuracy                           1.00     40000\n",
      "   macro avg       1.00      1.00      1.00     40000\n",
      "weighted avg       1.00      1.00      1.00     40000\n",
      "\n",
      "\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.92      8524\n",
      "           1       0.52      0.10      0.17      1476\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.69      0.54      0.54     10000\n",
      "weighted avg       0.81      0.85      0.81     10000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model: GaussianNB()\n",
      "\n",
      "Training Accuracy_Score: 0.828375\n",
      "\n",
      "Testing Accuracy_Score: 0.823\n",
      "\n",
      "Training AUC_Score: 0.5286045649940126\n",
      "\n",
      "Testing AUC_Score: 0.5152456510487208\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.90     33998\n",
      "           1       0.29      0.10      0.15      6002\n",
      "\n",
      "    accuracy                           0.83     40000\n",
      "   macro avg       0.57      0.53      0.53     40000\n",
      "weighted avg       0.77      0.83      0.79     40000\n",
      "\n",
      "\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      8524\n",
      "           1       0.22      0.08      0.12      1476\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.54      0.52      0.51     10000\n",
      "weighted avg       0.76      0.82      0.79     10000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model: MultinomialNB()\n",
      "\n",
      "Training Accuracy_Score: 0.617025\n",
      "\n",
      "Testing Accuracy_Score: 0.6136\n",
      "\n",
      "Training AUC_Score: 0.5924402780107476\n",
      "\n",
      "Testing AUC_Score: 0.5795197745501622\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.63      0.74     33998\n",
      "           1       0.21      0.56      0.30      6002\n",
      "\n",
      "    accuracy                           0.62     40000\n",
      "   macro avg       0.55      0.59      0.52     40000\n",
      "weighted avg       0.79      0.62      0.67     40000\n",
      "\n",
      "\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.63      0.73      8524\n",
      "           1       0.20      0.53      0.29      1476\n",
      "\n",
      "    accuracy                           0.61     10000\n",
      "   macro avg       0.54      0.58      0.51     10000\n",
      "weighted avg       0.78      0.61      0.67     10000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    clf = model\n",
    "    clf.fit(x_train,y_train)\n",
    "    print(\"Model:\",model)\n",
    "    print(\"\\nTraining Accuracy_Score:\",accuracy_score(y_train,clf.predict(x_train)))\n",
    "    print(\"\\nTesting Accuracy_Score:\",accuracy_score(y_test,clf.predict(x_test)))\n",
    "    print(\"\\nTraining AUC_Score:\",roc_auc_score(y_train,clf.predict(x_train)))\n",
    "    print(\"\\nTesting AUC_Score:\",roc_auc_score(y_test,clf.predict(x_test)))\n",
    "    print(\"\\nTraining Classification Report:\\n\",classification_report(y_train, clf.predict(x_train)))\n",
    "    print(\"\\nTesting Classification Report:\\n\",classification_report(y_test, clf.predict(x_test)))\n",
    "    print(\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
